testjob:
  only:
    - master
    - dev
    - dev-staging
  script:
    # !!kill coverage in case of hanging processes
    - if pgrep coverage; then pkill -f coverage; fi
    # set env
    - export PYTHONPATH="/home/wenqi/.local/lib/python2.7/site-packages":$PYTHONPATH
    - export PATH="/home/wenqi/.local/bin":$PATH

    # print system info
    - which nvidia-smi
    - nvidia-smi
    - pwd
    - python -c "import tensorflow as tf; print tf.__version__"
    - python -c "import tensorflow as tf; from tensorflow.python.client import device_lib; print device_lib.list_local_devices()"
    - ls -la /dev | grep nvidia

    - echo $(python tests/get_gpu_index.py)
    - export CUDA_VISIBLE_DEVICES=$(python tests/get_gpu_index.py)

    # download data
    - wget -q https://www.dropbox.com/s/y7mdh4m9ptkibax/example_volumes.tar.gz
    - tar -xzvf example_volumes.tar.gz
    - wget -q https://www.dropbox.com/s/94wa4fl8f8k3aie/testing_data.tar.gz
    - tar -xzvf testing_data.tar.gz

    # run python code with coverage wrapper
    - coverage erase

    - coverage run -a --source . run_application.py train -c config/highres3dnet_config.txt --batch_size 1 --image_size 32 --label_size 32 --queue_length 5 --num_threads 2
    - coverage run -a --source . run_application.py inference -c config/highres3dnet_config.txt --batch_size 8 --image_size 64 --label_size 64 --queue_length 32

    - coverage run -a --source . run_application.py train -c config/scalenet_config.txt --batch_size 1 --image_size 32 --label_size 32 --queue_length 5 --num_threads 2
    - coverage run -a --source . run_application.py inference -c config/scalenet_config.txt --batch_size 16 --image_size 64 --label_size 64 --queue_length 32

    - coverage run -a --source . run_application.py train -c config/vnet_config.txt --batch_size 1 --image_size 32 --label_size 32 --queue_length 5 --num_threads 2 --activation_function relu
    - coverage run -a --source . run_application.py inference -c config/vnet_config.txt --batch_size 16 --image_size 64 --label_size 64 --queue_length 32 --activation_function relu

    # need a large GPU to run
    #- coverage run -a --source . run_application.py train -c config/unet_config.txt --batch_size 1 --image_size 96 --label_size 96 --queue_length 5 --num_threads 2
    #- coverage run -a --source . run_application.py inference -c config/unet_config.txt --batch_size 1 --image_size 96 --label_size 96 --queue_length 5

    #- coverage run -a --source . run_application.py train -c config/deepmedic_config.txt --batch_size 8 --queue_length 16 --num_threads 2
    #- coverage run -a --source . run_application.py inference -c config/deepmedic_config.txt --batch_size 64 --queue_length 96

    - coverage run -a --source . run_application.py train -c config/default_config.txt --image_size 42 --label_size 42 --batch_size 3 --queue_length 6
    - coverage run -a --source . run_application.py train -c config/default_config.txt --image_size 42 --label_size 42 --batch_size 3 --queue_length 6 --starting_iter 10 --max_iter 15
    - coverage run -a --source . run_application.py inference -c config/default_config.txt --image_size 84 --label_size 84 --batch_size 7 --queue_length 14

    - coverage run -a --source . run_application.py train -c config/default_multimodal_config.txt --image_size 42 --label_size 42 --batch_size 3
    - coverage run -a --source . run_application.py inference -c config/default_multimodal_config.txt --image_size 84 --label_size 84 --batch_size 7

    - coverage run -a --source . -m tests.mean_variance_normalisation_test
    - coverage run -a --source . -m tests.binary_masking_test
    - coverage run -a --source . -m tests.histogram_normalisation_test
    - coverage run -a --source . -m tests.activation_test
    - coverage run -a --source . -m tests.bn_test
    - coverage run -a --source . -m tests.convolution_test
    - coverage run -a --source . -m tests.deconvolution_test
    - coverage run -a --source . -m tests.downsample_test
    - coverage run -a --source . -m tests.elementwise_test
    - coverage run -a --source . -m tests.highres3dnet_test
    - coverage run -a --source . -m tests.highresblock_test
    - coverage run -a --source . -m tests.upsample_test
    - coverage run -a --source . -m tests.toynet_test
    - coverage run -a --source . -m tests.crop_test
    - coverage run -a --source . -m tests.deepmedic_test
    - coverage run -a --source . -m tests.vnetblock_test
    - coverage run -a --source . -m tests.vnet_test
    - coverage run -a --source . -m tests.unetblock_test
      #- coverage run -a --source . -m tests.unet_test
    - coverage run -a --source . -m tests.scaleblock_test
    - coverage run -a --source . -m tests.scalenet_test
    - coverage run -a --source . -m tests.toy_sampler_test
    - coverage run -a --source . -m tests.input_buffer_test
    - coverage run -a --source . -m tests.dilatedcontext_test
    - coverage run -a --source . -m tests.loss_test
    - coverage run -a --source . -m tests.subject_test
    - coverage run -a --source . -m tests.volume_loader_test
    - coverage run -a --source . -m tests.uniform_sampler_test
    - coverage run -a --source . -m tests.grid_sampler_test
    - coverage run -a --source . -m tests.selective_sampler_test
    - coverage run -a --source . -m tests.rand_rotation_test
    - coverage run -a --source . -m tests.rand_spatial_scaling_test
    - coverage run -a --source . -m tests.post_processing_test
    - coverage run -a --source . -m tests.spatial_transformer_test
    - coverage run -a --source . -m tests.rand_flip_test
    - coverage report -m
    - echo 'finished test'
  tags:
    - gift-linux

pip-installer:
  only:
    - 69-push-to-pip-repository-after-commit-to-master-off-dev
    - 69-push-to-pip-repository-after-commit-to-master-off-dev-restructure-hierarchy
  script:
    # following three lines copied over from dev script:
    - ls -la /dev | grep nvidia
    - echo $(python tests/get_gpu_index.py)
    - export CUDA_VISIBLE_DEVICES=$(python tests/get_gpu_index.py)
    # create a Python file that will import all available packages from the pip installer
    - package_importer="import_niftynet_packages.py"
    # traverse the file hierarchy recursively to discover all packages
    - find niftynet -type f \( ! -name . \) -print | grep '.py$' | grep -v __init__ | sed 's/\.\.\///g;s/\//\./g;s/\.py//g;s/niftynet/import niftynet/g' > $venv/$package_importer
    # save NiftyNet folder path just in case
    - niftynet_dir=$(pwd)
    # create a virtual env to test pip installer
    - venv="niftynet-pip-installer-venv-py2"
    - mypython=$(which python2)
    - virtualenv -p $mypython $venv
    - cd $venv
    - source bin/activate
    # install dependencies for GPU
    - pip install -r $niftynet_dir/requirements-gpu.txt
    - pip install simpleitk
    - pip install scikit-learn
    # install using setup.py in NiftyNet folder
    - pip install $niftynet_dir
    # check whether all packages are importable
    - cat $package_importer
    - python $package_importer
    # deactivate virtual environment
    - deactivate
  tags:
    - gift-adelie
